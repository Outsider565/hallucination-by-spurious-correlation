<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <meta name="title" content="When Bias Pretends to Be Truth: How Spurious Correlations Undermine Hallucination Detection in LLMs - Wang et al.">
  <meta name="description" content="Spurious correlations in training induce confident LLM hallucinations that persist with scaling and defeat confidence- and probing-based detectors.">
  <meta name="keywords" content="hallucination detection, spurious correlation, large language models, uncertainty, calibration, inner-state probing">
  <meta name="author" content="Shaowen Wang, Yiqi Dong, Ruinian Chang, Tansheng Zhu, Yuebo Sun, Kaifeng Lyu, Jian Li">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="IIIS, Tsinghua University">
  <meta property="og:title" content="When Bias Pretends to Be Truth: How Spurious Correlations Undermine Hallucination Detection in LLMs">
  <meta property="og:description" content="Spurious correlations in training induce confident LLM hallucinations that persist with scaling and defeat confidence- and probing-based detectors.">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="When Bias Pretends to Be Truth - Research Preview">
  <meta property="article:published_time" content="2026-01-01T00:00:00.000Z">
  <meta property="article:author" content="Shaowen Wang">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="KEYWORD1">
  <meta property="article:tag" content="KEYWORD2">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- TODO: Replace with your lab/institution Twitter handle -->
  <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE">
  <!-- TODO: Replace with first author's Twitter handle -->
  <meta name="twitter:creator" content="@AUTHOR_TWITTER_HANDLE">
  <!-- TODO: Same as paper title above -->
  <meta name="twitter:title" content="When Bias Pretends to Be Truth: How Spurious Correlations Undermine Hallucination Detection in LLMs">
  <!-- TODO: Same as description above -->
  <meta name="twitter:description" content="Spurious correlations in training induce confident LLM hallucinations that persist with scaling and defeat confidence- and probing-based detectors.">
  <!-- TODO: Same as social preview image above -->
  <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="PAPER_TITLE - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="When Bias Pretends to Be Truth: How Spurious Correlations Undermine Hallucination Detection in LLMs">
  <meta name="citation_author" content="Wang, Shaowen">
  <meta name="citation_author" content="Dong, Yiqi">
  <meta name="citation_author" content="Chang, Ruinian">
  <meta name="citation_author" content="Zhu, Tansheng">
  <meta name="citation_author" content="Sun, Yuebo">
  <meta name="citation_author" content="Lyu, Kaifeng">
  <meta name="citation_author" content="Li, Jian">
  <meta name="citation_publication_date" content="2025">
  <meta name="citation_conference_title" content="arXiv">
  <meta name="citation_pdf_url" content="https://arxiv.org/pdf/2511.07318.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <title>When Bias Pretends to Be Truth | Project Page</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "When Bias Pretends to Be Truth: How Spurious Correlations Undermine Hallucination Detection in LLMs",
    "description": "Spurious correlations in training induce confident LLM hallucinations that persist with scaling and defeat confidence- and probing-based detectors.",
    "author": [
      { "@type": "Person", "name": "Shaowen Wang", "affiliation": { "@type": "Organization", "name": "Institute for Interdisciplinary Information Sciences, Tsinghua University" } },
      { "@type": "Person", "name": "Yiqi Dong", "affiliation": { "@type": "Organization", "name": "Institute for Interdisciplinary Information Sciences, Tsinghua University" } },
      { "@type": "Person", "name": "Ruinian Chang", "affiliation": { "@type": "Organization", "name": "Institute for Interdisciplinary Information Sciences, Tsinghua University" } },
      { "@type": "Person", "name": "Tansheng Zhu", "affiliation": { "@type": "Organization", "name": "Institute for Interdisciplinary Information Sciences, Tsinghua University" } },
      { "@type": "Person", "name": "Yuebo Sun", "affiliation": { "@type": "Organization", "name": "Institute for Interdisciplinary Information Sciences, Tsinghua University" } },
      { "@type": "Person", "name": "Kaifeng Lyu", "affiliation": { "@type": "Organization", "name": "Institute for Interdisciplinary Information Sciences, Tsinghua University" } },
      { "@type": "Person", "name": "Jian Li", "affiliation": { "@type": "Organization", "name": "Institute for Interdisciplinary Information Sciences, Tsinghua University" } }
    ],
    "datePublished": "2025",
    "publisher": {
      "@type": "Organization",
      "name": "arXiv"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "static/images/Figure1.jpg",
    "keywords": ["hallucination detection", "spurious correlation", "large language models", "uncertainty", "calibration", "inner-state probing"],
    "abstract": "Despite substantial advances, large language models (LLMs) continue to exhibit hallucinations, generating plausible yet incorrect responses. In this paper, we highlight a critical yet previously underexplored class of hallucinations driven by spurious correlations—superficial but statistically prominent associations between features (e.g., surnames) and attributes (e.g., nationality) present in the training data. We demonstrate that these spurious correlations induce hallucinations that are confidently generated, immune to model scaling, evade current detection methods, and persist even after refusal fine-tuning. Through systematically controlled synthetic experiments and empirical evaluations on state-of-the-art open-source and proprietary LLMs (including GPT-5), we show that existing hallucination detection methods, such as confidence-based filtering and inner-state probing, fundamentally fail in the presence of spurious correlations. Our theoretical analysis further elucidates why these statistical biases intrinsically undermine confidence-based detection techniques. Our findings thus emphasize the urgent need for new approaches explicitly designed to address hallucinations caused by spurious correlations.",
    "citation": "@article{wang2025bias, title={When Bias Pretends to Be Truth: How Spurious Correlations Undermine Hallucination Detection in LLMs}, author={Wang, Shaowen and Dong, Yiqi and Chang, Ruinian and Zhu, Tansheng and Sun, Yuebo and Lyu, Kaifeng and Li, Jian}, journal={arXiv preprint arXiv:2511.07318}, year={2025}, url={https://arxiv.org/abs/2511.07318} }",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "Institute for Interdisciplinary Information Sciences, Tsinghua University",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "logo": "https://YOUR_DOMAIN.com/static/images/favicon.ico",
    "sameAs": [
      "https://twitter.com/YOUR_TWITTER_HANDLE",
      "https://github.com/YOUR_GITHUB_USERNAME"
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

	  <!-- More Works Dropdown removed (no related works listed yet) -->

  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
	            <h1 class="title is-1 publication-title">When Bias Pretends to Be Truth: How Spurious Correlations Undermine Hallucination Detection in LLMs</h1>
            <div class="is-size-5 publication-authors">
	              <span class="author-block">Shaowen Wang<sup>*</sup>,</span>
	              <span class="author-block">Yiqi Dong<sup>*</sup>,</span>
	              <span class="author-block">Ruinian Chang<sup>*</sup>,</span>
	              <span class="author-block">Tansheng Zhu<sup>*</sup>,</span>
	              <span class="author-block">Yuebo Sun,</span>
	              <span class="author-block">Kaifeng Lyu,</span>
	              <span class="author-block">Jian Li<sup>&dagger;</sup></span>
	            </div>

                  <div class="is-size-5 publication-authors">
	                    <span class="author-block">Institute for Interdisciplinary Information Sciences, Tsinghua University</span>
	                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
	                    <div class="publication-links">
		                    <!-- Only Code and arXiv links are shown for now -->
		                  <span class="link-block">
		                    <!-- TODO: Update with your code repository URL -->
			                    <a href="https://github.com/Outsider565/hallucination-by-spurious-correlation-code" target="_blank"
			                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

	                <span class="link-block">
	                  <!-- TODO: Update with your arXiv link -->
		                  <a href="https://arxiv.org/abs/2511.07318" target="_blank"
		                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser figure -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/Figure1.jpg" alt="Teaser figure: spurious correlations induce confident hallucinations" loading="lazy"/>
      <h2 class="subtitle has-text-centered">
        Spurious correlations induce high-confidence hallucinations that evade detection and mitigation.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser figure -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
	          <p>
	            Despite substantial advances, large language models (LLMs) continue to exhibit hallucinations, generating plausible yet incorrect responses. In this paper, we highlight a critical yet previously underexplored class of hallucinations driven by spurious correlations—superficial but statistically prominent associations between features (e.g., surnames) and attributes (e.g., nationality) present in the training data. We demonstrate that these spurious correlations induce hallucinations that are confidently generated, immune to model scaling, evade current detection methods, and persist even after refusal fine-tuning. Through systematically controlled synthetic experiments and empirical evaluations on state-of-the-art open-source and proprietary LLMs (including GPT-5), we show that existing hallucination detection methods, such as confidence-based filtering and inner-state probing, fundamentally fail in the presence of spurious correlations. Our theoretical analysis further elucidates why these statistical biases intrinsically undermine confidence-based detection techniques. Our findings thus emphasize the urgent need for new approaches explicitly designed to address hallucinations caused by spurious correlations.
	          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Results -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 has-text-centered">Results</h2>
      </div>
    </div>
  </div>
</section>

<!-- Section 1 -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h3 class="title is-4">1. Spurious correlations break hallucination detection in controlled settings</h3>
        <div class="content has-text-justified">
          <p>
            We induce spurious surname–attribute correlations with strength ρ and evaluate a suite of confidence‑based
            and inner‑state probing detectors. In both pretraining and knowledge‑injection regimes, detectors that work
            well at ρ = 0 degrade sharply as ρ increases, often approaching random performance. This shows a
            robust failure mode: spurious correlations create hallucinations that look “confident” to existing detectors.
          </p>
        </div>
        <div class="columns is-centered is-variable is-6">
          <div class="column is-half">
            <figure class="image">
              <img src="static/images/bios_auroc.png" alt="AUROC vs spurious correlation in pretraining" loading="lazy"/>
            </figure>
            <p class="has-text-centered is-size-7">Pretraining setting.</p>
          </div>
          <div class="column is-half">
            <figure class="image">
              <img src="static/images/smollm_auroc.png" alt="AUROC vs spurious correlation after knowledge injection" loading="lazy"/>
            </figure>
            <p class="has-text-centered is-size-7">Knowledge‑injection setting.</p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Section 2 -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h3 class="title is-4">2. Spurious correlations defeat refusal fine‑tuning and factual recall</h3>
        <div class="content has-text-justified">
          <p>
            We fine‑tune models with refusal examples (“I don’t know”) and test factual recall on known entities and refusal
            on unknown ones. As spurious correlation strengthens, recall accuracy drops and refusal rates fall, and this
            degradation persists across model sizes. Scaling does not rescue either capability, indicating that spurious
            correlations undermine both knowledge retrieval and uncertainty‑aware behavior.
          </p>
        </div>
        <div class="columns is-centered is-variable is-6">
          <div class="column is-half">
            <figure class="image">
              <img src="static/images/1_acc_vs_prob.png" alt="Accuracy under spurious correlation across model sizes" loading="lazy"/>
            </figure>
            <p class="has-text-centered is-size-7">Accuracy on known individuals.</p>
          </div>
          <div class="column is-half">
            <figure class="image">
              <img src="static/images/2_refusal_vs_prob.png" alt="Refusal rate under spurious correlation across model sizes" loading="lazy"/>
            </figure>
            <p class="has-text-centered is-size-7">Refusal rate on unknown individuals.</p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Section 3 -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h3 class="title is-4">3. Real LLMs become more confidently wrong as spurious correlation increases</h3>
        <div class="content has-text-justified">
          <p>
            In real‑world QA, we proxy spurious correlation using entity co‑occurrence (Jaccard overlap) in Wikipedia.
            Across frontier open‑source and API models, higher overlap leads to higher self‑reported confidence and higher
            self‑consistency, even when answers are incorrect. This mirrors the synthetic findings: stronger associative
            priors make hallucinations more confident.
          </p>
        </div>
        <figure class="image">
          <img src="static/images/llm_confidence.png" alt="Self-confidence and self-consistency vs entity co-occurrence" loading="lazy"/>
        </figure>
        <p class="has-text-centered is-size-7">Left: mean self‑confidence; Right: mean self‑consistency (10 runs).</p>
      </div>
    </div>
  </div>
</section>

<!-- Section 4 -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h3 class="title is-4">4. Detection performance collapses under strong entity co‑occurrence</h3>
        <div class="content has-text-justified">
          <p>
            We evaluate the same detectors on GPT‑OSS‑20B and Qwen3‑30B‑A3B‑Instruct over SimpleQA. As entity overlap
            increases, AUROC falls for all methods, including perplexity‑ and entropy‑based scores and linear probes.
            Spurious correlations in real data therefore reproduce the controlled failure mode at scale.
          </p>
        </div>
        <figure class="image">
          <img src="static/images/llm_detection.png" alt="Hallucination detection AUROC vs entity co-occurrence" loading="lazy"/>
        </figure>
        <p class="has-text-centered is-size-7">Left: GPT‑OSS‑20B; Right: Qwen3‑30B‑A3B‑Instruct.</p>
      </div>
    </div>
  </div>
</section>

<!-- Section 5 -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h3 class="title is-4">5. Theoretical understanding: why confidence fails under spurious correlation</h3>
        <div class="content has-text-justified">
          <p>
            We analyze a toy data model that separates a shortcut (correlation) region from a noisy region. Any learning
            method that generalizes well must exploit the shortcut features in the correlation region, which yields
            uniformly high‑confidence predictions there—even on unseen inputs. As a result, confidence‑based hallucination
            detectors cannot distinguish “seen” from “unseen” facts when spurious correlations are strong. In contrast,
            a degenerate memorization regime can make detection easy, but only by sacrificing generalization.
          </p>
        </div>
        <div class="columns is-centered is-variable is-6">
          <div class="column is-half">
            <figure class="image">
              <img src="static/images/illu_mlp.png" alt="Toy model illustrating correlation and noisy regions" loading="lazy"/>
            </figure>
            <p class="has-text-centered is-size-7">Toy setting with correlation vs noisy regions.</p>
          </div>
          <div class="column is-half">
            <figure class="image">
              <img src="static/images/mlp_result.png" alt="Detection AUROC vs shortcut proportion in toy model" loading="lazy"/>
            </figure>
            <p class="has-text-centered is-size-7">Detection AUROC decreases as shortcut proportion ρ increases.</p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- End results -->



<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
	      <pre id="bibtex-code"><code>@article{wang2025bias,
  title={When Bias Pretends to Be Truth: How Spurious Correlations Undermine Hallucination Detection in LLMs},
  author={Wang, Shaowen and Dong, Yiqi and Chang, Ruinian and Zhu, Tansheng and Sun, Yuebo and Lyu, Kaifeng and Li, Jian},
  journal={arXiv preprint arXiv:2511.07318},
  year={2025}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
